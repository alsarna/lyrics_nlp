{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metallic-universal",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import billboard\n",
    "import json\n",
    "import re\n",
    "import lyricsgenius\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import requests\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-national",
   "metadata": {},
   "source": [
    "### Genius and Spotify APIs' settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genius token\n",
    "genius_token = os.environ.get('genius_token')\n",
    "\n",
    "# Spotify authorization\n",
    "spotify_client_id = os.environ.get('spotify_client_id')\n",
    "spotify_client_secret = os.environ.get('spotify_client_secret')\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=spotify_client_id, client_secret=spotify_client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-concord",
   "metadata": {},
   "source": [
    "### CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data and adding year columns and wrapping up billboard songs (1950-2015)\n",
    "wd = os.getcwd()\n",
    "data_path = os.chdir(wd + '\\data')\n",
    "all_csv_files = os.listdir(data_path)\n",
    "songs_50_15 = []\n",
    "\n",
    "for filename in all_csv_files:\n",
    "    songs = pd.read_csv(filename, header = 0, sep = ';')\n",
    "    year = os.path.basename(filename)[:-4]\n",
    "    songs['Year'] = year\n",
    "    songs_50_15.append(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-walker",
   "metadata": {},
   "source": [
    "### billboard library data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading data from years 2016-2020 from billboard library\n",
    "playlist = 'hot-100-songs'\n",
    "dates = [2016, 2017, 2018, 2019, 2020]\n",
    "songs_billboard = []\n",
    "for y in dates:\n",
    "    songs = billboard.ChartData(playlist, date = None, year = y, fetch = True, timeout = 25)\n",
    "    songs_billboard.append(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-distribution",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocessing data from years 2016-2020\n",
    "song_titles, artists = [[] for i in range(2)]\n",
    "\n",
    "for year in songs_billboard:\n",
    "    for playlist in year:\n",
    "        song = str(playlist).split(' by ')\n",
    "        song_titles.append(song[0].strip(\"\\'\"))\n",
    "        artists.append(song[1])\n",
    "        \n",
    "# Adding missed song on 87th position in 2016 chart\n",
    "song_titles.insert(86, 'All the Way Up')\n",
    "artists.insert(86, 'Fat Joe, Remy Ma and Jay-Z featuring French Montana and Infared')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-memorabilia",
   "metadata": {},
   "source": [
    "### Concatenating CSV and billboard library data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# Splitting list into same-length elements lists\n",
    "def list_split(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))\n",
    "\n",
    "split_artists = list(list_split(artists, 100))\n",
    "split_song_titles = list(list_split(song_titles, 100))\n",
    "\n",
    "# Creating list of dictionaries for each year to convert them into pandas DataFrame\n",
    "def dicts_of_dates(lst_of_dates):\n",
    "    songs = []\n",
    "    for i in range(len(lst_of_dates)):\n",
    "        ranger = list(range(1, 101))\n",
    "        year = lst_of_dates[i]\n",
    "        dictionary = {'Position': ranger, 'Artist': split_artists[i], 'Song Title': split_song_titles[i], 'Year': [dates[i] for year in range(1, 101)]}\n",
    "        as_pandas_df = pd.DataFrame(dictionary)\n",
    "        songs.append(as_pandas_df)\n",
    "    return songs\n",
    "\n",
    "# Concatenate all songs from years 1950 - 2020\n",
    "songs_16_20 = dicts_of_dates(dates)\n",
    "all_songs = songs_50_15 + songs_16_20\n",
    "all_time_billboard_wrap_up = pd.concat(all_songs)\n",
    "all_time_billboard_wrap_up.reset_index(drop = True, inplace = True) # reset indexing\n",
    "display(all_time_billboard_wrap_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_time_billboard_wrap_up dataframe nans checking\n",
    "nans_table = [all_time_billboard_wrap_up['Position'].isna().any(), all_time_billboard_wrap_up['Artist'].isna().any(), all_time_billboard_wrap_up['Song Title'].isna().any(), all_time_billboard_wrap_up['Year'].isna().any()]\n",
    "nans_proj = pd.DataFrame({'Column': ['Position', 'Artist', 'Song Title', 'Year'], 'Is nan?': nans_table}).set_index('Column')\n",
    "display(nans_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# Spliting authors by 'and' and 'Featuring' to make api searching easier and more efficient\n",
    "artists = list(all_time_billboard_wrap_up.loc[:,'Artist'])\n",
    "split_artists = []\n",
    "for artist in artists:\n",
    "    if any(re.findall(r'and|featuring|feat.|Featuring|Feat.&', str(artist))):\n",
    "        result = re.split(r'and|featuring|feat.|Featuring|Feat.&', str(artist))[0].strip()\n",
    "        split_artists.append(result)\n",
    "    else:\n",
    "        split_artists.append(artist)\n",
    "\n",
    "all_time_billboard_wrap_up['Split Names'] = split_artists\n",
    "display(all_time_billboard_wrap_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-fitting",
   "metadata": {},
   "source": [
    "### Genius data into json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyricsgenius settings\n",
    "genius = lyricsgenius.Genius(genius_token, timeout = 30, retries = 3)\n",
    "songs = list(all_time_billboard_wrap_up.loc[:, 'Song Title'])\n",
    "artists = list(all_time_billboard_wrap_up.loc[:,'Split Names'])\n",
    "jsons_path = wd + '\\\\jsons\\\\'\n",
    "\n",
    "# Saving lyrics to jsons function\n",
    "def return_lyrics_json(song, artist, json_name):\n",
    "    song_lyrics = genius.search_song(song, artist)\n",
    "    with open(jsons_path + json_name, 'w', encoding = 'UTF-8') as f:\n",
    "        json.dump({'lyrics': song_lyrics.lyrics}, f, ensure_ascii = False, indent = 4)\n",
    "\n",
    "# No lyrics function (only instrumental songs)\n",
    "def no_lyrics(json_name):\n",
    "    with open(jsons_path + json_name, 'w', encoding = 'UTF-8') as f:\n",
    "        json.dump({'lyrics': \"\"}, f, ensure_ascii = False, indent = 4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying return_lyrics_json and no_lyrics functions on lyrics:\n",
    "def json_data():\n",
    "    error_list = []\n",
    "    for i in range(len(songs)):\n",
    "        try:\n",
    "            return_lyrics_json(songs[i], artists[i], str(i)+'.json')\n",
    "        except AttributeError:\n",
    "            no_lyrics(str(i)+'.json')\n",
    "            error_list.append(i)\n",
    "# json_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# err based on error_list\n",
    "# Fixed 6140 Beyonce 7/11 (date format in csv)\n",
    "err = [12, 23, 25, 53, 60, 74, 84, 100, 101, 103, 111, 116, 141, 160, 173, 190, 196, 210, 233, 239, 266, 277, 334, 365, 380, 385, 386, 401, 428, 439, 440, 448, 501, 515, 519, 537, 554, 565, 604, 616, 619, 633, 690, 694, 696, 708, 723, 771, 774, 784, 800, 816, 832, 838, 853, 862, 866, 871, 906, 920, 937, 969, 991, 1039, 1111, 1126, 1150, 1180, 1211, 1245, 1277, 1381, 1387, 1397, 1400, 1422, 1454, 1537, 1542, 1569, 1598, 1613, 1615, 1668, 1801, 1807, 1822, 1850, 1873, 1895, 1940, 1965, 1982, 2027, 2095, 2144, 2167, 2177, 2189, 2208, 2269, 2350, 2370, 2400, 2528, 2559, 2603, 2633, 2690, 2738, 2791, 2835, 2843, 3140, 3334, 3460, 3742, 3908, 3952, 4121, 4169, 4171, 4180, 4208, 4244, 4245, 4280, 4351, 4361, 4387, 4518, 4579, 4760, 4777, 4823, 5134, 5235]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-asset",
   "metadata": {},
   "source": [
    "### Deleting empty or invalid json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting empty json files\n",
    "# Adding string '.json' to err\n",
    "json_delete = [str(j) + '.json' for j in err]\n",
    "# Deteling json files that are in json_delete list and bigger than 5KB\n",
    "all_json_files = os.listdir(jsons_path)\n",
    "for x in all_json_files:\n",
    "    filepath = jsons_path + str(x)\n",
    "    json_size = os.path.getsize(filepath)\n",
    "    if (json_size > 5 * 1024) or (x in err): #error_list\n",
    "        os.remove(filepath)\n",
    "# Selecting all_billboard_wrap_up data corresponding with actual list of jsons\n",
    "ordered_jsons = sorted([int(x[:-5]) for x in os.listdir(jsons_path)])\n",
    "all_time_billboard_wrap_up_cleaned = all_time_billboard_wrap_up.iloc[ordered_jsons]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-deadline",
   "metadata": {},
   "source": [
    "### Spotify IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# Function that enables finding Spotify ID from spotipy\n",
    "def find_spotify_id(artist, track):\n",
    "    try:\n",
    "        track_id = spotipy.search(q='artist:' + artist + ' track:' + track, type='track')\n",
    "        return track_id['tracks']['items'][0]['id']\n",
    "    except IndexError:\n",
    "        return ''    \n",
    "all_time_billboard_wrap_up_cleaned['Spotify ID'] = [find_spotify_id(all_time_billboard_wrap_up_cleaned['Split Names'].iloc[i], all_time_billboard_wrap_up_cleaned['Song Title'].iloc[i]) for i in range(len(all_time_billboard_wrap_up_cleaned))]\n",
    "display(all_time_billboard_wrap_up_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "sum(all_time_billboard_wrap_up_cleaned['Spotify ID'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check artist and song name for n Spotify IDs\n",
    "spotify_ids = all_time_billboard_wrap_up_cleaned['Spotify ID'].tolist()\n",
    "spotify_artists = []\n",
    "spotify_songs = []\n",
    "for i in range(0, len(spotify_ids)):\n",
    "    if spotify_ids[i] != '':\n",
    "        track = spotipy.track(spotify_ids[i])\n",
    "        song_name = track['name']\n",
    "        spotify_songs.append(song_name)\n",
    "        artist = track['album']['artists'][0].get('name')\n",
    "        spotify_artists.append(artist)\n",
    "    else:\n",
    "        song_name, artist = '', ''\n",
    "        spotify_songs.append(song_name)\n",
    "        spotify_artists.append(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_billboard_wrap_up_cleaned['Spotify Artist'] = spotify_artists\n",
    "all_time_billboard_wrap_up_cleaned['Spotify Song'] = spotify_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_billboard_wrap_up_cleaned_sp_data = all_time_billboard_wrap_up_cleaned[all_time_billboard_wrap_up_cleaned['Spotify Artist'].isin(all_time_billboard_wrap_up_cleaned['Artist'])]\n",
    "display(all_time_billboard_wrap_up_cleaned_sp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-newsletter",
   "metadata": {},
   "source": [
    "### Spotify audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_time_billboard_wrap_up_cleaned_sp_data['Spotify ID']:\n",
    "    df = pd.DataFrame(sp.audio_features(i))\n",
    "    all_time_billboard_wrap_up_cleaned_sp_data = all_time_billboard_wrap_up_cleaned_sp_data.merge(df, how = 'left', left_on = 'Spotify ID', right_on = 'id')\n",
    "display(all_time_billboard_wrap_up_cleaned_sp_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
